{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "import sys\n",
    "import csv\n",
    "import math\n",
    "import h5py\n",
    "\n",
    "operating_system = sys.platform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This file is for turning the h5 data to a compatible csv file.\n",
    "# In writeToCSV the data (in dictionaries) is written in a csv\n",
    "# In convertH5Data the data from h5 is handled to calculate the coordinates and putting the data in a dictionary\n",
    "\n",
    "# Change the code below to the folder/path of the h5 files (location)\n",
    "# Target_location is where the csv data are written to\n",
    "location = 'RadarData'\n",
    "target_location = 'csvData'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add heights\n",
    "\n",
    "Add heights voegt de data van de radarbeelden van verschillende elevation angles samen tot een lijst met dictionaries met DBZH waarden en coordinaten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_heights(datasets):\n",
    "    points = []\n",
    "    for data in datasets:\n",
    "        if (data != \"how\" and data != \"what\" and data != \"where\"):\n",
    "            elevation_angle = datasets[data][\"where\"].attrs.values()[1]\n",
    "            nbins = datasets[data][\"where\"].attrs.values()[2]\n",
    "            nrays = datasets[data][\"where\"].attrs.values()[3]\n",
    "            bin_distance = datasets[data][\"where\"].attrs.values()[4]\n",
    "            data_DBZH = datasets[data][\"data1\"][\"data\"][()]\n",
    "            data_TH = datasets[data][\"data2\"][\"data\"][()]\n",
    "            data_VRAD = datasets[data][\"data3\"][\"data\"][()]\n",
    "            offsets = [datasets[data][\"data1\"][\"what\"].attrs.values()[1], datasets[data][\"data2\"][\"what\"].attrs.values()[1], datasets[data][\"data3\"][\"what\"].attrs.values()[1]]\n",
    "            gains = [datasets[data][\"data1\"][\"what\"].attrs.values()[0], datasets[data][\"data2\"][\"what\"].attrs.values()[0], datasets[data][\"data3\"][\"what\"].attrs.values()[0]]\n",
    "            points.extend(get_coordinates_picture(nbins, nrays, elevation_angle, bin_distance, data_DBZH, data_TH, data_VRAD, offsets, gains))\n",
    "    return points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get coordinates picture\n",
    "Get coordinates picture brekent van elke ray de XYZ coordinaten ens laat deze in een lijst van dictionaries op samen met de DBZH waardes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get_coordinates_picture berekent van elk punt in een radarafbeelding de bijbehorende x,y en z coordinaat\n",
    "# deze worden opgeslagen in een lijst van dictionaries samen met de DBZH waarde van elk punt.\n",
    "def get_coordinates_picture(nbins, nrays, elevation_angle, bin_distance, data_DBZH, data_TH, data_VRAD, offsets, gains):\n",
    "    pic = []\n",
    "    for bin_number in range(nbins):\n",
    "        for ray_number in range(nrays):\n",
    "            xyz = get_xyz(elevation_angle, bin_number, bin_distance, ray_number, nrays)\n",
    "            tmp = {\"DBZH\": offsets[0] + data_DBZH[ray_number][bin_number]*gains[0], \"TH\":offsets[1] + data_TH[ray_number][bin_number]*gains[1],\n",
    "            \"VRAD\":offsets[2] + data_VRAD[ray_number][bin_number] * gains[2], \"x\": xyz[0], \"y\": xyz[1], \"z\": xyz[2]}\n",
    "            pic.append(tmp)\n",
    "    return pic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get XYZ\n",
    "get_xyz berekent de x, y en z coordinaat van een radarbin. \n",
    "  \n",
    "INPUT:  \n",
    "elevation angle: de hoek van de radarbeam t.o.v. de grond  \n",
    "bin_number: de n-de radarbin van een beam  \n",
    "bin_distance: de afstand tussen de radarbins  \n",
    "angle_number: de n-de beam van de radar in de x-y richting  \n",
    "total_angles: het totaal aantal beams wat is genomen in een rondje  \n",
    "  \n",
    "OUTPUT:  \n",
    "de x, y, en z coordinaat van de radabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_xyz(elevation_angle, bin_number, bin_distance, angle_number, total_angles):\n",
    "    z = bin_number * bin_distance * math.sin(math.radians(elevation_angle))\n",
    "    dis = bin_number * bin_distance * math.cos(math.radians(elevation_angle))\n",
    "    beam_angle = (math.radians(float(angle_number)/total_angles) * 360)\n",
    "    y = dis * math.cos(beam_angle)\n",
    "    x = dis * math.sin(beam_angle)\n",
    "    return [x,y,z]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert H5 file to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convertH5toCSV(h5file, csvfileName):\n",
    "    # Get data from h5 file\n",
    "    datasets = h5py.File(h5file, 'r')\n",
    "\n",
    "    # Convert h5 file to xyz\n",
    "    points = add_heights(datasets) # From convertH5Data\n",
    "\n",
    "    # Export points to csv file\n",
    "    createCSVfile(csvfileName, points) # From writeToCSV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Radar Data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def importData(location, newpath):\n",
    "    matches = []\n",
    "    # Get all h5 radar files in the radarData directory\n",
    "    for root, dirnames, filenames in os.walk(location):\n",
    "        for filename in fnmatch.filter(filenames, '*.h5'):\n",
    "            matches.append(os.path.join(root, filename))\n",
    "    if operating_system == 'windows':\n",
    "        # Convert all H5 files to csv files\n",
    "        for h5file in matches:\n",
    "            split = h5file.split('\\\\') # [day, hour, quarter of an hour]\n",
    "            if not os.path.exists(newpath+split[1]):\n",
    "                os.makedirs(newpath+split[1])\n",
    "            csvFileName = newpath+\"\\\\\"+split[1]+\"\\\\\"+split[1]+\"-\"+split[2]+\"-\"+split[3]+\".csv\"\n",
    "            convertH5toCSV(h5file, csvFileName)\n",
    "    else:\n",
    "        # Convert all H5 files to csv files\n",
    "        for h5file in matches:\n",
    "            split = h5file.split('/') # [day, hour, quarter of an hour]\n",
    "            regexResult = split\n",
    "            if not os.path.exists(newpath+\"/\"+split[1]):\n",
    "                os.makedirs(newpath+\"/\"+split[1])\n",
    "            csvFileName = newpath+\"/\"+split[1]+\"/\"+split[1]+\"-\"+split[2]+\"-\"+split[3]+\".csv\"\n",
    "            convertH5toCSV(h5file, csvFileName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# We have used the same threshold as the KNMI where everything below a dBZH value of -31 is clutter\n",
    "threshold = -31.0\n",
    "# Create or overwrite a csv file with 6 colomns, each containing a feature or coordinate.\n",
    "def createCSVfile(fileName, data):\n",
    "    print fileName\n",
    "\n",
    "    with open(fileName, 'w') as csvfile:\n",
    "\t\t# These are the features stored each in a different colomn\n",
    "        fieldnames = ['DBZH', 'TH', 'VRAD','x', 'y', 'z']\n",
    "        # Write the features to a dictionary\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "        # Write a row with the specified fieldnames\n",
    "        writer.writeheader()\n",
    "\n",
    "        # Recursively write a row\n",
    "        for point in data:\n",
    "            if point['DBZH'] > threshold:\n",
    "                writer.writerow(point)\n",
    "        print 'is created.'\n",
    "        csvfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************** Creating CSV files *******************************\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "global name 'time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d118ea439aaa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-d118ea439aaa>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"******************** Creating CSV files *******************************\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimportData\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_location\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0;34m\"********************* CSV files created ********************************\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'time' is not defined"
     ]
    }
   ],
   "source": [
    "def main(argv):\n",
    "    print \"******************** Creating CSV files *******************************\"\n",
    "    importData(location, target_location)\n",
    "    print \"********************* CSV files created ********************************\"\n",
    "    pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
